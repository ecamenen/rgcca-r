% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rgccad.R
\name{rgccad}
\alias{rgccad}
\title{Regularized Generalized Canonical Correlation Analysis (RGCCA)}
\usage{
rgccad(
  blocks,
  connection = 1 - diag(length(blocks)),
  tau = rep(1, length(blocks)),
  ncomp = rep(1, length(blocks)),
  scheme = "centroid",
  init = "svd",
  bias = TRUE,
  tol = 1e-08,
  verbose = TRUE,
  na.rm = TRUE,
  quiet = FALSE
)
}
\arguments{
\item{blocks}{A list that contains the J blocks of variables X1, X2, ..., XJ.
Block Xj is a matrix of dimension n x p_j where n is the number of
observations and p_j the number of variables.}

\item{connection}{A symmetric matrix (J*J) that describes the relationships between
blocks.}

\item{tau}{Either a 1*J vector or a max(ncomp)*J matrix containing
the values of the regularization parameters (default: tau = 1, for each
block and each dimension). The regularization parameters varies from 0
(maximizing the correlation) to 1 (maximizing the covariance). If
tau = "optimal" the regularization paramaters are estimated for each block
and each dimension using the Schafer and Strimmer (2005) analytical formula.
If tau is a 1*J vector, tau[j] is identical across the dimensions
of block Xj. If tau is a matrix, tau[k, j] is associated with
X_jk (kth residual matrix for block j). The regularization parameters can
also be estimated using \link{rgcca_permutation} or \link{rgcca_cv}.}

\item{ncomp}{Vector of length J indicating the number of block components
for each block.}

\item{scheme}{Character string or a function giving the scheme function for
covariance maximization among "horst" (the identity function), "factorial"
 (the squared values), "centroid" (the absolute values). The scheme function
 can be any continously differentiable convex function and it is possible to
 design explicitely the sheme function (e.g. function(x) x^4) as argument of
 rgcca function.  See (Tenenhaus et al, 2017) for details.}

\item{init}{Character string giving the type of initialization to use in
the  algorithm. It could be either by Singular Value Decompostion ("svd")
or by random initialisation ("random") (default: "svd").}

\item{bias}{A logical value for biaised (\eqn{1/n}) or unbiaised
(\eqn{1/(n-1)}) estimator of the var/cov (default: bias = TRUE).}

\item{tol}{The stopping value for the convergence of the algorithm.}

\item{verbose}{Logical value indicating if the progress of the
algorithm is reported while computing.}

\item{na.rm}{If TRUE, runs rgcca only on available data.}

\item{quiet}{Logical value indicating if warning messages are reported.}
}
\value{
\item{Y}{A list of \eqn{J} elements. Each element of the list is a
matrix that contains the RGCCA block components for the corresponding block.}

\item{a}{A list of \eqn{J} elements. Each element of the list \eqn{a}
is a matrix of block weight vectors for the corresponding block.}

\item{astar}{A list of \eqn{J} elements. Each element of astar is a
matrix defined as Y[[j]][, h] = blocks[[j]]\%*\%astar[[j]][, h].}

\item{tau}{Either a 1*J vector or a \eqn{\mathrm{max}(ncomp) \times J}
matrix containing the values of the regularization parameters. tau varies
from 0 (maximizing the correlation) to 1 (maximizing the covariance).
If tau = "optimal" the regularization paramaters are estimated for each
block and each dimension using the Schafer and Strimmer (2005) analytical
formula. If tau is a \eqn{1\times J} vector, tau[j] is identical across the
dimensions of block \eqn{\mathbf{X}_j}. If tau is a matrix, tau[k, j] is
associated with \eqn{\mathbf{X}_{jk}} (\eqn{k}th residual matrix for
block \eqn{j}). tau can be also estimated using \link{rgcca_permutation}.}

\item{crit}{A list of vector of length max(ncomp). Each vector of
the list is related to one specific deflation stage and reports the values
of the criterion for this stage across iterations.}

\item{primal_dual}{A \eqn{1 \times J} vector that contains the
formulation ("primal" or "dual") applied to each of the \eqn{J} blocks within
the RGCCA alogrithm.}

\item{AVE}{A list of numerical values giving the goodness of fit
the model based on the Average Variance Explained (AVE): AVE(for each block),
AVE(outer model), AVE(inner model).}
}
\description{
Regularized Generalized Canonical Correlation Analysis (RGCCA) is a
generalization of regularized canonical correlation analysis to three or more
sets of variables.
}
\details{
Given \eqn{J} matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}}
that represent \eqn{J} sets of variables observed on the same set of \eqn{n}
individuals. The matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}}
must have the same number of rows, but may (and usually will) have different
numbers of columns. The aim of RGCCA is to study  the relationships between
these \eqn{J} blocks of variables. It constitutes a general framework for
many multi-block data analysis methods. It combines the power of multi-block
data analysis methods (maximization of well identified criteria) and the
flexibility of PLS path modeling (the researcher decides which blocks are
connected and which are not). Hence, the use of RGCCA requires the
construction (user specified) of a design matrix, (\eqn{\mathbf{connection}}), that
characterize the connections between blocks. Elements of the (symmetric)
design matrix \eqn{\mathbf{connection} = (c_{jk})} is positive ; but usually equal to 1
if block \eqn{j} and block \eqn{k} are connected, and 0 otherwise. The
objective is to find a stationnary point related to the RGCCA optimization
problem. The function rgccad() implements a globally convergent algorithm
(i.e. monotone convergence that hits at convergence a stationary point).
Moreover, depending on the dimensionality of each block \eqn{\mathbf{X}_j},
\eqn{j = 1, \ldots, J}, the primal (when \eqn{n > p_j}) algorithm or
the dual (when \eqn{n < p_j}) algorithm is used (see Tenenhaus et al. 2015).
Moreover, by deflation strategy, rgccad() allow to compute several RGCCA
block components (specified by ncomp) for each block. Using deflation, within
each block, block components are guaranteed to be orthogonal. The so-called
symmetric deflation is considered in this implementation, i.e. each block is
deflated with respect to its own component. It should be noted that the
numbers of components per block can differ from one block to another.
The rgcca() function can handle missing values using a NIPALS type algorithm
(non-linear iterative partial least squares algorithm) as described in
(Tenenhaus et al, 2005).
}
\examples{
#############
# Example 1 #
#############
data(Russett)
X_agric =as.matrix(Russett[,c("gini","farm","rent")])
X_ind = as.matrix(Russett[,c("gnpr","labo")])
X_polit = as.matrix(Russett[ , c("demostab", "dictator")])
blocks = list(X_agric, X_ind, X_polit)
#Define the design matrix (output = connection)
connection = matrix(c(0, 0, 1, 0, 0, 1, 1, 1, 0), 3, 3)
fit.rgcca = rgccad(blocks, connection, tau = c(1, 1, 1), scheme = "factorial")
lab = as.vector(apply(Russett[, 9:11], 1, which.max))
plot(fit.rgcca$Y[[1]], fit.rgcca$Y[[2]], col = "white",
     xlab = "Y1 (Agric. inequality)", ylab = "Y2 (Industrial Development)")
text(fit.rgcca$Y[[1]], fit.rgcca$Y[[2]], rownames(Russett),
     col = lab, cex = .7)

############################################
# Example 2: RGCCA and mutliple components #
############################################
############################
# plot(y1, y2) for (RGCCA) #
############################
fit.rgcca = rgccad(blocks, connection, tau = rep(1, 3), ncomp = c(2, 2, 1),
                     scheme = "factorial", verbose = TRUE)
layout(t(1:2))
plot(fit.rgcca$Y[[1]][, 1], fit.rgcca$Y[[2]][, 1], col = "white",
xlab = "Y1 (Agric. inequality)", ylab = "Y2 (Industrial Development)",
main = "Factorial plan of RGCCA")
text(fit.rgcca$Y[[1]][, 1], fit.rgcca$Y[[2]][, 1], rownames(Russett),
col = lab, cex = .6)
plot(fit.rgcca$Y[[1]][, 1], fit.rgcca$Y[[1]][, 2], col = "white",
xlab = "Y1 (Agric. inequality)", ylab = "Y2 (Agric. inequality)",
main = "Factorial plan of RGCCA")
text(fit.rgcca$Y[[1]][, 1], fit.rgcca$Y[[1]][, 2], rownames(Russett),
col = lab, cex = .6)

######################################
# example 3: RGCCA and leave one out #
######################################
Ytest = matrix(0, 47, 3)
fit.rgcca = rgccad(blocks, connection, tau = rep(1, 3), ncomp = rep(1, 3),
                     scheme = "factorial", verbose = TRUE)
for (i in 1:nrow(Russett)){
 B = lapply(blocks, function(x) x[-i, ])
 B = lapply(B, scale)

 resB = rgccad(B, connection, tau = rep(1, 3), scheme = "factorial", verbose = FALSE)
 #  look for potential conflicting sign among components within the loo loop.
 for (k in 1:length(B)){
   if (cor(fit.rgcca$a[[k]], resB$a[[k]]) >= 0)
     resB$a[[k]] = resB$a[[k]] else resB$a[[k]] = -resB$a[[k]]
 }
 Btest = lapply(blocks, function(x) x[i, ])
 Btest[[1]] = (Btest[[1]]-attr(B[[1]],"scaled:center"))/
                  (attr(B[[1]],"scaled:scale"))
 Btest[[2]] = (Btest[[2]]-attr(B[[2]],"scaled:center"))/
                  (attr(B[[2]],"scaled:scale"))
 Btest[[3]] = (Btest[[3]]-attr(B[[3]],"scaled:center"))/
                  (attr(B[[3]],"scaled:scale"))
 Ytest[i, 1] = Btest[[1]]\%*\%resB$a[[1]]
 Ytest[i, 2] = Btest[[2]]\%*\%resB$a[[2]]
 Ytest[i, 3] = Btest[[3]]\%*\%resB$a[[3]]
}
lab = apply(Russett[, 9:11], 1, which.max)
plot(fit.rgcca$Y[[1]], fit.rgcca$Y[[2]], col = "white",
     xlab = "Y1 (Agric. inequality)", ylab = "Y2 (Ind. Development)")
text(fit.rgcca$Y[[1]], fit.rgcca$Y[[2]], rownames(Russett), col = lab)
text(Ytest[, 1], Ytest[, 2], substr(rownames(Russett), 1, 1), col = lab)
}
\references{
Tenenhaus M., Tenenhaus A. and Groenen P. J. (2017). Regularized
generalized canonical correlation analysis: a framework for sequential
multiblock component methods. Psychometrika, 82(3), 737-777.

Tenenhaus A., Philippe C. and Frouin, V. (2015). Kernel
generalized canonical correlation analysis. Computational Statistics and
Data Analysis, 90, 114-131.

Tenenhaus A. and Tenenhaus M., (2011). Regularized Generalized
Canonical Correlation Analysis, Psychometrika, Vol. 76, Nr 2, pp 257-284.

Schafer J. and Strimmer K. (2005). A shrinkage approach to
large-scale covariance matrix estimation and implications for functional
genomics. Statist. Appl. Genet. Mol. Biol. 4:32.
}
